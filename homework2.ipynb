{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 요구사항 1",
   "id": "6fd54d37178e7c1e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-18T07:55:51.160565Z",
     "start_time": "2025-10-18T07:54:57.039390Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "BASE_PATH = \"/Users/leodi/git/link_dl\" # BASE_PATH: /Users/yhhan/git/link_dl\n",
    "print(\"BASE_PATH:\", BASE_PATH)\n",
    "\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "# 기존 캘리포니아 데이터셋 대신 과제에 맞는 타이타닉 데이터셋 가져옴\n",
    "from _03_homeworks.homework_2.titanic_dataset import get_preprocessed_dataset\n",
    "\n",
    "\n",
    "def get_data():\n",
    "  #기존에는 훈련/검증 데이터셋만 사용했지만, 최종 제출을 위해 테스트 데이터셋까지 모두 불러옴\n",
    "  train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "  print(train_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "  train_data_loader = DataLoader(dataset=train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "  test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "  return train_data_loader, validation_data_loader, test_data_loader\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__()\n",
    "\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_model_and_optimizer():\n",
    "  # 타이타닉 데이터의 feature 개수 10개와 클래스 개수(사망/생존) 2개에 맞게 모델 입출력 크기 수정\n",
    "  my_model = MyModel(n_input=10, n_output=2)\n",
    "  optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "  return my_model, optimizer\n",
    "\n",
    "\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  n_epochs = wandb.config.epochs\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  # 회귀 문제용 MSELoss 대신, 분류 문제에 적합한 CrossEntropyLoss로 변경\n",
    "  next_print_epoch = 100\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    loss_train = 0.0\n",
    "    num_trains = 0\n",
    "    for train_batch in train_data_loader:\n",
    "      input, target = train_batch['input'], train_batch['target']\n",
    "      output_train = model(input)\n",
    "      loss = loss_fn(output_train, target)\n",
    "      loss_train += loss.item()\n",
    "      num_trains += 1\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    model.eval() # 평가 모드로 설정하여 정확한 성능 측정\n",
    "    loss_validation = 0.0\n",
    "    num_validations = 0\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in validation_data_loader:\n",
    "        input, target = validation_batch['input'], validation_batch['target']\n",
    "        output_validation = model(input)\n",
    "        loss = loss_fn(output_validation, target)\n",
    "        loss_validation += loss.item()\n",
    "        num_validations += 1\n",
    "\n",
    "    wandb.log({\n",
    "      \"Epoch\": epoch,\n",
    "      \"Training loss\": loss_train / num_trains,\n",
    "      \"Validation loss\": loss_validation / num_validations,\n",
    "    })\n",
    "\n",
    "    if epoch >= next_print_epoch:\n",
    "      print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "        f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "      )\n",
    "      next_print_epoch += 100\n",
    "\n",
    "\n",
    "def main(config):\n",
    "  current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  wandb.init(\n",
    "    mode=\"online\" if config['wandb'] else \"disabled\",\n",
    "    project=\"my_model_training_titanic\",\n",
    "    notes=\"My first wandb experiment\",\n",
    "    tags=[\"my_model\", \"titanic\"],\n",
    "    name=current_time_str,\n",
    "    config=config\n",
    "  )\n",
    "  print(wandb.config)\n",
    "\n",
    "  train_data_loader, validation_data_loader, _ = get_data()\n",
    "\n",
    "  linear_model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  training_loop(\n",
    "    model=linear_model,\n",
    "    optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader,\n",
    "    validation_data_loader=validation_data_loader\n",
    "  )\n",
    "  wandb.finish()\n",
    "\n",
    "\n",
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "  # argparse 대신, Jupyter Notebook에서 실험하기 편하도록 config 딕셔너리 사용\n",
    "  config = {\n",
    "      \"wandb\": True,\n",
    "      \"batch_size\": 16,\n",
    "      \"epochs\": 1_000,\n",
    "      \"learning_rate\": 0.01,\n",
    "      \"n_hidden_unit_list\": [20, 20]\n",
    "  }\n",
    "\n",
    "  main(config)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_PATH: /Users/leodi/git/link_dl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\leodi\\git\\link_dl\\_04_your_code\\wandb\\run-20251018_165457-ybz52dbe</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimwonho-/my_model_training_titanic/runs/ybz52dbe' target=\"_blank\">2025-10-18_16-54-57</a></strong> to <a href='https://wandb.ai/kimwonho-/my_model_training_titanic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/kimwonho-/my_model_training_titanic' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/kimwonho-/my_model_training_titanic/runs/ybz52dbe' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic/runs/ybz52dbe</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wandb': True, 'batch_size': 16, 'epochs': 1000, 'learning_rate': 0.01, 'n_hidden_unit_list': [20, 20]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leodi\\git\\link_dl\\_03_homeworks\\homework_2\\titanic_dataset.py:128: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"alone\"].fillna(0, inplace=True)\n",
      "C:\\Users\\leodi\\git\\link_dl\\_03_homeworks\\homework_2\\titanic_dataset.py:147: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x00000126488789D0> <torch.utils.data.dataset.Subset object at 0x00000126488780A0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5203, Validation loss 0.5792\n",
      "Epoch 200, Training loss 0.4584, Validation loss 0.5296\n",
      "Epoch 300, Training loss 0.4555, Validation loss 0.6313\n",
      "Epoch 400, Training loss 0.4332, Validation loss 0.6019\n",
      "Epoch 500, Training loss 0.4091, Validation loss 0.5620\n",
      "Epoch 600, Training loss 0.4059, Validation loss 0.5937\n",
      "Epoch 700, Training loss 0.3894, Validation loss 0.6887\n",
      "Epoch 800, Training loss 0.3945, Validation loss 0.6311\n",
      "Epoch 900, Training loss 0.3762, Validation loss 0.6619\n",
      "Epoch 1000, Training loss 0.3767, Validation loss 0.5991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>Training loss</td><td>█▇▆▆▅▅▅▄▄▅▅▃▄▃▂▂▃▃▂▃▃▂▂▃▂▃▂▂▂▂▂▂▂▂▂▁▂▁▂▂</td></tr><tr><td>Validation loss</td><td>▃▃▃▃▅▂▁▁▂▁▂█▃▂▁▁▄▂▂▃▃▃▄▃▃▅▆█▄▅▄▄▅▄▅▃▄▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.37673</td></tr><tr><td>Validation loss</td><td>0.59914</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-10-18_16-54-57</strong> at: <a href='https://wandb.ai/kimwonho-/my_model_training_titanic/runs/ybz52dbe' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic/runs/ybz52dbe</a><br> View project at: <a href='https://wandb.ai/kimwonho-/my_model_training_titanic' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251018_165457-ybz52dbe\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 기술적 사항 / 고찰 내용\n",
    "요구사항1은 회귀 문제용으로 설계된 c_my_model_training_with_argparse_wandb.py 코드를  Titanic 생존자 예측이라는 분류 문제에 맞게 변환하는 것이었습니다. 이를 위해 먼저 데이터 로딩 부분을 titanic_dataset.py를 사용하도록 수정했으며, 데이터의 특성 10개와 목표 2개에 맞춰 모델의 입력과 출력을 각각 10과 2로 변경했습니다. 그리고 문제 유형이 회귀에서 분류로 바뀜에 따라서 손실 함수를 기존의 nn.MSELoss에서 분류 문제에 적합한 nn.CrossEntropyLoss로 교체했습니다. 마지막으로, argparse 모듈을 제거하고 Jupyter Notebook 환경에서의 실험을 위해 config 딕셔너리 방식으로 변경했습니다. 또한, 내용을 wandb를 통해 기록하여  분석의 기반을 마련했습니다."
   ],
   "id": "23a8cde632b05526"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 요구사항 2",
   "id": "3099b01dfecc353a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T08:28:49.733797Z",
     "start_time": "2025-10-18T08:28:31.448556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "BASE_PATH = \"/Users/leodi/git/link_dl\" # BASE_PATH: /Users/yhhan/git/link_dl\n",
    "print(\"BASE_PATH:\", BASE_PATH)\n",
    "\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _03_homeworks.homework_2.titanic_dataset import get_preprocessed_dataset\n",
    "\n",
    "\n",
    "def get_data():\n",
    "  train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "  print(train_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "  train_data_loader = DataLoader(dataset=train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "  test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "  return train_data_loader, validation_data_loader, test_data_loader\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__()\n",
    "\n",
    "    # 비교를 위하여 Sigmoid, ReLU, ELU, Leaky ReLU로 변경해 가면서 실험\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "      nn.ELU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "      nn.ELU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_model_and_optimizer():\n",
    "  my_model = MyModel(n_input=10, n_output=2)\n",
    "  optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "  return my_model, optimizer\n",
    "\n",
    "\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  n_epochs = wandb.config.epochs\n",
    "  loss_fn = nn.CrossEntropyLoss()  # Use a built-in loss function\n",
    "  next_print_epoch = 100\n",
    "\n",
    "  lowest_validation_loss = float('inf')\n",
    "  lowest_validation_loss_epoch = 0\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    loss_train = 0.0\n",
    "    num_trains = 0\n",
    "    for train_batch in train_data_loader:\n",
    "      input, target = train_batch['input'], train_batch['target']\n",
    "      output_train = model(input)\n",
    "      loss = loss_fn(output_train, target)\n",
    "      loss_train += loss.item()\n",
    "      num_trains += 1\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    loss_validation = 0.0\n",
    "    num_validations = 0\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in validation_data_loader:\n",
    "        input, target = validation_batch['input'], validation_batch['target']\n",
    "        output_validation = model(input)\n",
    "        loss = loss_fn(output_validation, target)\n",
    "        loss_validation += loss.item()\n",
    "        num_validations += 1\n",
    "\n",
    "    avg_loss_validation = loss_validation / num_validations\n",
    "    avg_loss_train = loss_train / num_trains\n",
    "\n",
    "    # 가장 낮은 validation loss와 그때의 epoch을 기록\n",
    "    if avg_loss_validation < lowest_validation_loss:\n",
    "        lowest_validation_loss = avg_loss_validation\n",
    "        lowest_validation_loss_epoch = epoch\n",
    "\n",
    "    wandb.log({\n",
    "      \"Epoch\": epoch,\n",
    "      \"Training loss\": avg_loss_train,\n",
    "      \"Validation loss\": avg_loss_validation,\n",
    "      \"Lowest Validation loss\": lowest_validation_loss,\n",
    "      \"Lowest Validation loss epoch\": lowest_validation_loss_epoch,\n",
    "    })\n",
    "\n",
    "    if epoch >= next_print_epoch:\n",
    "      print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Training loss {avg_loss_train:.4f}, \"\n",
    "        f\"Validation loss {avg_loss_validation:.4f}\"\n",
    "      )\n",
    "      next_print_epoch += 100\n",
    "\n",
    "\n",
    "def main(config):\n",
    "  current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  wandb.init(\n",
    "    mode=\"online\" if config['wandb'] else \"disabled\",\n",
    "    project=\"my_model_training_titanic\",\n",
    "    notes=\"My first wandb experiment\",\n",
    "    tags=[\"my_model\", \"titanic\"],\n",
    "    name=current_time_str,\n",
    "    config=config\n",
    "  )\n",
    "  print(wandb.config)\n",
    "\n",
    "  train_data_loader, validation_data_loader, _ = get_data()\n",
    "\n",
    "  linear_model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  training_loop(\n",
    "    model=linear_model,\n",
    "    optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader,\n",
    "    validation_data_loader=validation_data_loader\n",
    "  )\n",
    "  wandb.finish()\n",
    "\n",
    "\n",
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "  config = {\n",
    "      \"wandb\": True,\n",
    "      \"batch_size\": 128,\n",
    "      \"epochs\": 1_000,\n",
    "      \"learning_rate\": 0.01,\n",
    "      \"n_hidden_unit_list\": [20, 20]\n",
    "  }\n",
    "\n",
    "  main(config)"
   ],
   "id": "1bb0d63f3470586a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_PATH: /Users/leodi/git/link_dl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\leodi\\git\\link_dl\\_04_your_code\\wandb\\run-20251018_172831-17xtclt8</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimwonho-/my_model_training_titanic/runs/17xtclt8' target=\"_blank\">2025-10-18_17-28-31</a></strong> to <a href='https://wandb.ai/kimwonho-/my_model_training_titanic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/kimwonho-/my_model_training_titanic' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/kimwonho-/my_model_training_titanic/runs/17xtclt8' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic/runs/17xtclt8</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wandb': True, 'batch_size': 128, 'epochs': 1000, 'learning_rate': 0.01, 'n_hidden_unit_list': [20, 20]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leodi\\git\\link_dl\\_03_homeworks\\homework_2\\titanic_dataset.py:128: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"alone\"].fillna(0, inplace=True)\n",
      "C:\\Users\\leodi\\git\\link_dl\\_03_homeworks\\homework_2\\titanic_dataset.py:147: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x00000126488665C0> <torch.utils.data.dataset.Subset object at 0x00000126488679A0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5702, Validation loss 0.5553\n",
      "Epoch 200, Training loss 0.5551, Validation loss 0.5526\n",
      "Epoch 300, Training loss 0.5339, Validation loss 0.4862\n",
      "Epoch 400, Training loss 0.5471, Validation loss 0.5562\n",
      "Epoch 500, Training loss 0.5412, Validation loss 0.4642\n",
      "Epoch 600, Training loss 0.4680, Validation loss 0.4466\n",
      "Epoch 700, Training loss 0.5089, Validation loss 0.5311\n",
      "Epoch 800, Training loss 0.4446, Validation loss 0.4353\n",
      "Epoch 900, Training loss 0.4428, Validation loss 0.5992\n",
      "Epoch 1000, Training loss 0.4416, Validation loss 0.5420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>Lowest Validation loss</td><td>█████▇▇▇▆▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Lowest Validation loss epoch</td><td>▁▁▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██████████</td></tr><tr><td>Training loss</td><td>██▇▇▇▆▇▆▆▆▅▄▆▅▄▅▅▅▃▃▃▅▄▃▂▅▃▂▃▁▂▂▅▁▃▂▄▃▁▃</td></tr><tr><td>Validation loss</td><td>▄▄▃▃▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▃▁▁▃▁▃▂▂▁▂▁▃▂▁▂█▃▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Lowest Validation loss</td><td>0.42472</td></tr><tr><td>Lowest Validation loss epoch</td><td>815</td></tr><tr><td>Training loss</td><td>0.44158</td></tr><tr><td>Validation loss</td><td>0.54197</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-10-18_17-28-31</strong> at: <a href='https://wandb.ai/kimwonho-/my_model_training_titanic/runs/17xtclt8' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic/runs/17xtclt8</a><br> View project at: <a href='https://wandb.ai/kimwonho-/my_model_training_titanic' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251018_172831-17xtclt8\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 기술적 사항 / 고찰 내용",
   "id": "9baf0995c44e541c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![이미지](https://i.imgur.com/aUvvLA6.png)",
   "id": "f0ec639830ff5969"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![이미지2](https://i.imgur.com/pnlVhtl.png)",
   "id": "8984febc43fd0e55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "요구사항 2는 모델의 성능을 최적화하기 위해서 Activation Function과 Batch Size 두 가지를 체계적으로 실험하고 최적의 조합을 선택하는 내용이었습니다.\n",
    "먼저 배치 사이즈를 16으로 고정한 상태에서 Sigmoid, ReLU, ELU, Leaky ReLU 네 가지 Activation Function에 대한 성능 비교 실험을 진행했습니다. 첨부된 Wandb 그래프에서 확인할 수 있듯이, 각 활성화 함수는 훈련 과정에서 뚜렷한 차이를 보였습니다. 실험 결과, ELU가 가장 낮은 Validation loss 값을 기록해 최고의 성능을 보였습니다.\n",
    "다음으로, 가장 성능이 좋았던 ELU를 고정한 상태에서 배치 사이즈를 16, 32, 64, 128로 변경하며 실험을 진행했습니다. 그 결과, 배치 사이즈 32에서 가장 낮은 Validation loss를 기록하였기에 최적의 배치 사이즈로 보았습니다.너무 작은 배치 사이즈는 학습을 불안정하게 만들고, 너무 큰 배치 사이즈는 계산 비효율성과 Local Minima에 빠질 위험을 높인다는 내용이 있었는데 결과 또한 그것을 보여준다고 생각했습니다.\n",
    "최종적으로 Activation Function은 ELU, Batch Size는 32를 사용할 때 가장 좋은 성능을 보임을 알 수 있었습니다."
   ],
   "id": "c1bd17424941c0ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 요구사항 3",
   "id": "89a036266d3b0cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T09:10:59.682183Z",
     "start_time": "2025-10-18T09:10:28.817359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  n_epochs = wandb.config.epochs\n",
    "  loss_fn = nn.CrossEntropyLoss()  # Use a built-in loss function\n",
    "  next_print_epoch = 100\n",
    "\n",
    "  lowest_validation_loss = float('inf')\n",
    "  lowest_validation_loss_epoch = 0\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    loss_train = 0.0\n",
    "    num_trains = 0\n",
    "    for train_batch in train_data_loader:\n",
    "      input, target = train_batch['input'], train_batch['target']\n",
    "      output_train = model(input)\n",
    "      loss = loss_fn(output_train, target)\n",
    "      loss_train += loss.item()\n",
    "      num_trains += 1\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    loss_validation = 0.0\n",
    "    num_validations = 0\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in validation_data_loader:\n",
    "        input, target = validation_batch['input'], validation_batch['target']\n",
    "        output_validation = model(input)\n",
    "        loss = loss_fn(output_validation, target)\n",
    "        loss_validation += loss.item()\n",
    "        num_validations += 1\n",
    "\n",
    "    avg_loss_validation = loss_validation / num_validations\n",
    "    avg_loss_train = loss_train / num_trains\n",
    "\n",
    "    if avg_loss_validation < lowest_validation_loss:\n",
    "        lowest_validation_loss = avg_loss_validation\n",
    "        lowest_validation_loss_epoch = epoch\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        # 현재 validation loss가 기록된 최저 validation loss보다 낮으면, 모델 파라미터를 파일로 저장\n",
    "\n",
    "    wandb.log({\n",
    "      \"Epoch\": epoch,\n",
    "      \"Training loss\": avg_loss_train,\n",
    "      \"Validation loss\": avg_loss_validation,\n",
    "      \"Lowest Validation loss\": lowest_validation_loss,\n",
    "      \"Lowest Validation loss epoch\": lowest_validation_loss_epoch,\n",
    "    })\n",
    "\n",
    "    if epoch >= next_print_epoch:\n",
    "      print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Training loss {avg_loss_train:.4f}, \"\n",
    "        f\"Validation loss {avg_loss_validation:.4f}\"\n",
    "      )\n",
    "      next_print_epoch += 100\n",
    "\n",
    "# 훈련만 진행하도록 변경\n",
    "def main(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  training_loop(\n",
    "      model=model,\n",
    "      optimizer=optimizer,\n",
    "      train_data_loader=train_data_loader,\n",
    "      validation_data_loader=validation_data_loader\n",
    "  )\n",
    "\n",
    "def generate_submission(model, test_data_loader):\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\")) # 훈련 중 저장된 최고 성능의 모델 파라미터를 불러옴\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_batch in test_data_loader:\n",
    "            input_test = test_batch['input']\n",
    "            output_test = model(input_test)\n",
    "\n",
    "            # 모델의 출력에서 가장 높은 값의 인덱스(0 또는 1)를 최종 예측으로 선택\n",
    "            predicted_test = torch.argmax(output_test, dim=-1)\n",
    "            all_predictions.extend(predicted_test.numpy())\n",
    "\n",
    "    # 캐글 제출 형식에 맞게 submission.csv 파일 생성\n",
    "    test_csv_path = os.path.join(BASE_PATH, \"_03_homeworks\", \"homework_2\", \"test.csv\")\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": all_predictions\n",
    "    })\n",
    "\n",
    "    submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "\n",
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "  # 요구사항 2에서 확인했던 가장 성능이 좋았던 batch_size 32로 설정\n",
    "  config = {\n",
    "      \"wandb\": True,\n",
    "      \"batch_size\": 32,\n",
    "      \"epochs\": 1_000,\n",
    "      \"learning_rate\": 0.01,\n",
    "      \"n_hidden_unit_list\": [20, 20]\n",
    "  }\n",
    "\n",
    "  # Wandb 초기화\n",
    "  current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "  wandb.init(\n",
    "      mode=\"online\" if config['wandb'] else \"disabled\",\n",
    "      project=\"my_model_training_titanic\",\n",
    "      name=f\"ELU_batch{config['batch_size']}_{current_time_str}\",\n",
    "      config=config\n",
    "  )\n",
    "\n",
    "  # wandb가 초기화된 상태에서 필요한 모든 데이터와 모델을 준비\n",
    "  train_loader, validation_loader, test_loader = get_data()\n",
    "  my_model, my_optimizer = get_model_and_optimizer()\n",
    "\n",
    "  # 훈련을 실행하여 'best_model.pth' 파일을 생성\n",
    "  main(my_model, my_optimizer, train_loader, validation_loader)\n",
    "\n",
    "  # 훈련이 끝난 후, 저장된 최고 성능 모델을 사용하여 'submission.csv' 파일을 생성\n",
    "  generate_submission(my_model, test_loader)\n",
    "  wandb.finish()"
   ],
   "id": "34bbf4176444607c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\leodi\\git\\link_dl\\_04_your_code\\wandb\\run-20251018_181028-pf21lvix</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimwonho-/my_model_training_titanic/runs/pf21lvix' target=\"_blank\">ELU_batch32_2025-10-18_18-10-28</a></strong> to <a href='https://wandb.ai/kimwonho-/my_model_training_titanic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/kimwonho-/my_model_training_titanic' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/kimwonho-/my_model_training_titanic/runs/pf21lvix' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic/runs/pf21lvix</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leodi\\git\\link_dl\\_03_homeworks\\homework_2\\titanic_dataset.py:128: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"alone\"].fillna(0, inplace=True)\n",
      "C:\\Users\\leodi\\git\\link_dl\\_03_homeworks\\homework_2\\titanic_dataset.py:147: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x0000012648466FE0> <torch.utils.data.dataset.Subset object at 0x0000012648467220> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5299, Validation loss 0.7169\n",
      "Epoch 200, Training loss 0.4854, Validation loss 0.5150\n",
      "Epoch 300, Training loss 0.4558, Validation loss 0.4685\n",
      "Epoch 400, Training loss 0.4333, Validation loss 0.5082\n",
      "Epoch 500, Training loss 0.4258, Validation loss 0.4802\n",
      "Epoch 600, Training loss 0.4198, Validation loss 0.5149\n",
      "Epoch 700, Training loss 0.4356, Validation loss 0.5177\n",
      "Epoch 800, Training loss 0.4274, Validation loss 0.5705\n",
      "Epoch 900, Training loss 0.4052, Validation loss 0.4929\n",
      "Epoch 1000, Training loss 0.4214, Validation loss 0.6001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇█████</td></tr><tr><td>Lowest Validation loss</td><td>█▇▆▆▆▅▄▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Lowest Validation loss epoch</td><td>▁▁▂▂▂▅▆█████████████████████████████████</td></tr><tr><td>Training loss</td><td>██▇▇▇▅▆▅▅▆▅▄▄▄▄▃▃▄▄▃▃▃▂▃▃▂▂▂▂▃▂▃▂▂▁▂▁▃▁▁</td></tr><tr><td>Validation loss</td><td>▄▃▃▃▇▅▁▂▂▁▆▁▃█▄▂▁▂▁▁▃▃▃▂▃▃▆▂▃▄▁▂▁▂▃▄▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Lowest Validation loss</td><td>0.45134</td></tr><tr><td>Lowest Validation loss epoch</td><td>182</td></tr><tr><td>Training loss</td><td>0.42141</td></tr><tr><td>Validation loss</td><td>0.60013</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ELU_batch32_2025-10-18_18-10-28</strong> at: <a href='https://wandb.ai/kimwonho-/my_model_training_titanic/runs/pf21lvix' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic/runs/pf21lvix</a><br> View project at: <a href='https://wandb.ai/kimwonho-/my_model_training_titanic' target=\"_blank\">https://wandb.ai/kimwonho-/my_model_training_titanic</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251018_181028-pf21lvix\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 기술적 사항 / 고찰 내용\n",
    "요구사항3은 이전 단계에서 찾은 가장 좋은 성능을 보이는 Activation\tFunction 및 Batch Size로 모델 구성을 해서 Kaggle에 제출할 submission.csv 파일을 생성하는 내용이였습니다.\n",
    "먼저, 요구사항2의 실험 결과를 바탕으로, Activation\tFunction은 ELU, Batch Size는 32가 가장 낮은 Validation loss를 기록하여 이것을 바탕으로 최종 모델을 구성했습니다.\n",
    "submission.csv 생성을 위해 어떤 시점의 모델을 사용해야 하는지에 대한 고찰이 필요한데 이전 요구사항2에서의 실험을 보면 950번째 Epoch에서 Validation Loss가 0.40059로 최저점을 기록했습니다. Early Stopping 개념에 따르면, Validation loss의 최저점은 모델의 일반화 성능이 가장 높은 지점이며, 이 시점을 넘어서면 과적합으로 인해 성능이 저하될 수 있습니다. 그렇기에 이전 요구사항2에서의 경험을 바탕으로 진행하면 950번째 Epoch에서 저장된 모델을 이용하는게 가장 합리적이라고 생각하며, 이번 요구사항3에서는 182번째가 최저점이였으며, 이곳에서 저장된 모델을 사용하여 최종 테스트를 수행하는 것이 가장 좋은 결과가 나올 것이라고 생각하고 진행했습니다.\n",
    "위 내용을 바탕으로 추가 코딩을 진행했으며 Validation loss가 최저점을 기록할 때마다 torch.save(model.state_dict(), \"best_model.pth\") 코드를 통해 모델의 파라미터를 저장하도록 구현했습니다. 훈련이 모두 종료된 후에는 09.fcn_best_practice.pdf의 Tester 클래스 로직을 참고해서 generate_submission 함수를 구현했습니다. 그리고 Pandas 라이브러리를 활용하여 예측 결과를 PassengerId와 결합하고, submission.csv 파일로 생성했습니다.\n"
   ],
   "id": "4b8c1939f1423d98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 요구사항 4",
   "id": "388dc23685998d97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![캐글이미지](https://i.imgur.com/VvnP1xX.png)",
   "id": "c5cec60067cc5369"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "마지막 요구사항4에 적힌 내용대로 요구사항3에서 구한 submission.csv를 제출해서 저의 점수 및 위치를 스크린 이미지 캡쳐해서 마무리했습니다.",
   "id": "6f6414e16470dfb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 숙제 후기\n",
    "이번 과제는 본격적으로 딥러닝을 시도해보는 과제였다고 생각합니다. 그만큼 수업에서 들었던 내용을 직접 사용하면서 눈으로 확인하기에 좋았지만 처음하는 내용들이였기에 많은 시행착오를 겪어야 했습니다. 코드를 어떻게 수정해야할지 wandb에 연결한 데이터를 어떻게 비교해야 하는지 등 여러가지 요소가 있었지만 가장 기억에 남는 부분은 요구사항3에서 훈련과정 중 어느 Epoch\t시점에 테스트를 수행하여 submission.csv 를 구성해야 하는지 고찰하는 부분이 가장 기억에 남습니다. 훈련을 매번 다시 할 경우Validation loss가 최저점인 Epoch 값이 점점 달라지기에 한번의 훈련으로 나온 Epoch 값만 믿고 진행해도 될지도 고민했었습니다. 최종적으로는 현재 나온 Validation loss가 최저점인 Epoch에서 테스트를 수행하게 진행했지만 고민을 많이했던만큼 기억에 남는 것 같습니다.\n",
    "마지막으로, 첫 시도는 굉장히 힘들었지만 고민하면서 시도해가며 익숙해졌고 다음이 오면 더 체계적으로 진행할 수 있겠다는 생각이 들은 과제 였습니다."
   ],
   "id": "378c4c1723c059dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
