{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [시작 단계] 코드 수정해서 실행해보기",
   "id": "ebb880950ece277a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-11T07:09:05.995335Z",
     "start_time": "2025-11-11T07:09:02.176182Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "BASE_PATH = \"/Users/leodi/git/link_dl\"\n",
    "    #str(Path(__file__).resolve().parent.parent.parent))  # BASE_PATH: /Users/yhhan/git/link_dl\n",
    "print(BASE_PATH)\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "def get_num_cpu_cores():\n",
    "    import multiprocessing\n",
    "    return multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "def get_fashion_mnist_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
    "\n",
    "    print(\"Num Train Samples: \", len(f_mnist_train))\n",
    "    print(\"Num Validation Samples: \", len(f_mnist_validation))\n",
    "    print(\"Sample Shape: \", f_mnist_train[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    num_data_loading_workers = get_num_cpu_cores()\n",
    "    print(\"Number of Data Loading Workers:\", num_data_loading_workers)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2860, std=0.3529),\n",
    "    )\n",
    "\n",
    "    return train_data_loader, validation_data_loader, f_mnist_transforms\n",
    "\n",
    "\n",
    "def get_fashion_mnist_test_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
    "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
    "    print(\"Sample Shape: \", f_mnist_test[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test))\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2860, std=0.3529),\n",
    "    )\n",
    "\n",
    "    return f_mnist_test_images, test_data_loader, f_mnist_transforms\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {'batch_size': 2048, }\n",
    "    wandb.init(\n",
    "        mode=\"online\",\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    train_data_loader, validation_data_loader, f_mnist_transforms = get_fashion_mnist_data()\n",
    "    print()\n",
    "    f_mnist_test_images, test_data_loader, f_mnist_transforms = get_fashion_mnist_test_data()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leodi/git/link_dl\n",
      "Num Train Samples:  55000\n",
      "Num Validation Samples:  5000\n",
      "Sample Shape:  torch.Size([1, 28, 28])\n",
      "Number of Data Loading Workers: 16\n",
      "\n",
      "Num Test Samples:  10000\n",
      "Sample Shape:  torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [문제 1] Fashion MNIST 데이터 정규화를 위한 Mean과 std 값 찾기",
   "id": "3df2e236fde08704"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T07:38:06.622505Z",
     "start_time": "2025-11-11T07:37:59.699209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
    "\n",
    "imgs = torch.stack([img_t for img_t, _ in f_mnist_train], dim=3)\n",
    "print(imgs.shape)\n",
    "# >>> torch.Size([1, 28, 28, 55000])\n",
    "\n",
    "print(imgs.view(1, -1).mean(dim=-1))\n",
    "# >>> tensor([0.2860])\n",
    "\n",
    "print(imgs.view(1, -1).std(dim=-1))\n",
    "# >>> tensor([0.3529])"
   ],
   "id": "699bb8af75bfaf41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28, 55000])\n",
      "tensor([0.2860])\n",
      "tensor([0.3529])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 문제 1번 설명\n",
    "학습 데이터셋 전체를 하나의 텐서로 결합하여 픽셀 값의 분포를 분석했습니다. 데이터는 28x28 크기의 흑백 이미지 55,000장으로 구성되어 있으며 이를 바탕으로 전체 픽셀의 평균과 표준편차를 계산했습니다."
   ],
   "id": "9703d5e9d1c8bce1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [문제 2] Fashion MNIST 데이터에 대하여 CNN 학습시키기",
   "id": "2f071e43020b40ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:45:50.006811Z",
     "start_time": "2025-11-22T14:06:50.090842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from datetime import datetime\n",
    "import os\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "# !pip install torchinfo\n",
    "\n",
    "BASE_PATH = \"/Users/leodi/git/link_dl\"\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "CURRENT_FILE_PATH = str(Path.cwd())\n",
    "    #os.path.dirname(os.path.abspath(__file__)))\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "\n",
    "if not os.path.isdir(CHECKPOINT_FILE_PATH):\n",
    "  os.makedirs(os.path.join(CURRENT_FILE_PATH, \"checkpoints\"))\n",
    "\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def get_num_cpu_cores():\n",
    "    return os.cpu_count()\n",
    "\n",
    "class EarlyStopping:\n",
    "  \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "  def __init__(self, patience=10, delta=0.00001, project_name=None, checkpoint_file_path=None, run_time_str=None):\n",
    "    self.patience = patience\n",
    "    self.counter = 0\n",
    "    self.delta = delta\n",
    "\n",
    "    self.val_loss_min = None\n",
    "    self.file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_{run_time_str}.pt\"\n",
    "    )\n",
    "    self.latest_file_path = os.path.join(\n",
    "      checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "    )\n",
    "\n",
    "  def check_and_save(self, new_validation_loss, model):\n",
    "    early_stop = False\n",
    "\n",
    "    if self.val_loss_min is None:\n",
    "      self.val_loss_min = new_validation_loss\n",
    "      message = f'Early stopping is stated!'\n",
    "    elif new_validation_loss < self.val_loss_min - self.delta:\n",
    "      message = f'V_loss decreased ({self.val_loss_min:7.5f} --> {new_validation_loss:7.5f}). Saving model...'\n",
    "      self.save_checkpoint(new_validation_loss, model)\n",
    "      self.val_loss_min = new_validation_loss\n",
    "      self.counter = 0\n",
    "    else:\n",
    "      self.counter += 1\n",
    "      message = f'Early stopping counter: {self.counter} out of {self.patience}'\n",
    "      if self.counter >= self.patience:\n",
    "        early_stop = True\n",
    "        message += \" *** TRAIN EARLY STOPPED! ***\"\n",
    "\n",
    "    return message, early_stop\n",
    "\n",
    "  def save_checkpoint(self, val_loss, model):\n",
    "    '''Saves model when validation loss decrease.'''\n",
    "    torch.save(model.state_dict(), self.file_path)\n",
    "    torch.save(model.state_dict(), self.latest_file_path)\n",
    "    self.val_loss_min = val_loss\n",
    "\n",
    "from string import Template\n",
    "\n",
    "class DeltaTemplate(Template):\n",
    "    delimiter = \"%\"\n",
    "\n",
    "    def strfdelta(tdelta, fmt):\n",
    "        d = {\"D\": tdelta.days}\n",
    "        d[\"H\"], rem = divmod(tdelta.seconds, 3600)\n",
    "        d[\"M\"], d[\"S\"] = divmod(rem, 60)\n",
    "        t = DeltaTemplate(fmt)\n",
    "        return t.substitute(**d)\n",
    "\n",
    "def strfdelta(td, fmt):\n",
    "\n",
    "    # Get the timedelta’s sign and absolute number of seconds.\n",
    "    sign = \"-\" if td.days < 0 else \"+\"\n",
    "    secs = abs(td).total_seconds()\n",
    "\n",
    "    # Break the seconds into more readable quantities.\n",
    "    days, rem = divmod(secs, 86400)  # Seconds per day: 24 * 60 * 60\n",
    "    hours, rem = divmod(rem, 3600)  # Seconds per hour: 60 * 60\n",
    "    mins, secs = divmod(rem, 60)\n",
    "\n",
    "    # Format (as per above answers) and return the result string.\n",
    "    t = DeltaTemplate(fmt)\n",
    "    return t.substitute(\n",
    "        s=sign,\n",
    "        D=\"{:d}\".format(int(days)),\n",
    "        H=\"{:02d}\".format(int(hours)),\n",
    "        M=\"{:02d}\".format(int(mins)),\n",
    "        S=\"{:02d}\".format(int(secs)),\n",
    "        )\n",
    "\n",
    "\n",
    "class ClassificationTrainer:\n",
    "  def __init__(\n",
    "    self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "    run_time_str, wandb, device, checkpoint_file_path\n",
    "  ):\n",
    "    self.project_name = project_name\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.train_data_loader = train_data_loader\n",
    "    self.validation_data_loader = validation_data_loader\n",
    "    self.transforms = transforms\n",
    "    self.run_time_str = run_time_str\n",
    "    self.wandb = wandb\n",
    "    self.device = device\n",
    "    self.checkpoint_file_path = checkpoint_file_path\n",
    "\n",
    "    # Use a built-in loss function\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  def do_train(self):\n",
    "    self.model.train()  # Will be explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_train = 0.0\n",
    "    num_corrects_train = 0\n",
    "    num_trained_samples = 0\n",
    "    num_trains = 0\n",
    "\n",
    "    for train_batch in self.train_data_loader:\n",
    "      # input_train.shape: torch.Size([2048, 3, 32, 32]),  target_train.shape: torch.Size([2048])\n",
    "      input_train, target_train = train_batch\n",
    "      input_train = input_train.to(device=self.device)\n",
    "      target_train = target_train.to(device=self.device)\n",
    "\n",
    "      if self.transforms:\n",
    "        input_train = self.transforms(input_train)\n",
    "\n",
    "      output_train = self.model(input_train)\n",
    "      loss = self.loss_fn(output_train, target_train)\n",
    "      loss_train += loss.item()\n",
    "\n",
    "      predicted_train = torch.argmax(output_train, dim=-1)\n",
    "\n",
    "      # >>> predicted_train: tensor([5, 8, 9, 0, 9, 8, 9, 8, ..., 0, 1, 3, 7, 1, 4, 3])\n",
    "      # >>> target_train:    tensor([5, 8, 9, 2, 9, 8, 7, 8, ..., 4, 1, 9, 6, 1, 4, 3])\n",
    "      num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
    "\n",
    "      num_trained_samples += len(input_train)\n",
    "      num_trains += 1\n",
    "\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "    train_loss = loss_train / num_trains\n",
    "    train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "  def do_validation(self):\n",
    "    self.model.eval()   # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_corrects_validation = 0\n",
    "    num_validated_samples = 0\n",
    "    num_validations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in self.validation_data_loader:\n",
    "        input_validation, target_validation = validation_batch\n",
    "        input_validation = input_validation.to(device=self.device)\n",
    "        target_validation = target_validation.to(device=self.device)\n",
    "\n",
    "        if self.transforms:\n",
    "          input_validation = self.transforms(input_validation)\n",
    "\n",
    "        output_validation = self.model(input_validation)\n",
    "        loss_validation += self.loss_fn(output_validation, target_validation).item()\n",
    "\n",
    "        predicted_validation = torch.argmax(output_validation, dim=1)\n",
    "        num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
    "\n",
    "        num_validated_samples += len(input_validation)\n",
    "        num_validations += 1\n",
    "\n",
    "    validation_loss = loss_validation / num_validations\n",
    "    validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
    "\n",
    "    return validation_loss, validation_accuracy\n",
    "\n",
    "  def train_loop(self, scheduler=None):\n",
    "    early_stopping = EarlyStopping(\n",
    "      patience=self.wandb.config.early_stop_patience,\n",
    "      delta=self.wandb.config.early_stop_delta,\n",
    "      project_name=self.project_name,\n",
    "      checkpoint_file_path=self.checkpoint_file_path,\n",
    "      run_time_str=self.run_time_str\n",
    "    )\n",
    "    n_epochs = self.wandb.config.epochs\n",
    "    training_start_time = datetime.now()\n",
    "    max_val_accuracy = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      train_loss, train_accuracy = self.do_train()\n",
    "\n",
    "      if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "      if epoch == 1 or epoch % self.wandb.config.validation_intervals == 0:\n",
    "        validation_loss, validation_accuracy = self.do_validation()\n",
    "\n",
    "        elapsed_time = datetime.now() - training_start_time\n",
    "        epoch_per_second = 0 if elapsed_time.seconds == 0 else epoch / elapsed_time.seconds\n",
    "\n",
    "        message, early_stop = early_stopping.check_and_save(validation_loss, self.model)\n",
    "\n",
    "        if validation_accuracy > max_val_accuracy:\n",
    "            max_val_accuracy = validation_accuracy\n",
    "            best_epoch = epoch\n",
    "\n",
    "        print(\n",
    "          f\"[Epoch {epoch:>3}] \"\n",
    "          f\"T_loss: {train_loss:7.5f}, \"\n",
    "          f\"T_accuracy: {train_accuracy:6.4f} | \"\n",
    "          f\"V_loss: {validation_loss:7.5f}, \"\n",
    "          f\"V_accuracy: {validation_accuracy:6.4f} | \"\n",
    "          f\"Best V_Acc: {max_val_accuracy:6.4f} at Epoch {best_epoch} | \"\n",
    "          f\"{message} | \"\n",
    "          f\"T_time: {strfdelta(elapsed_time, '%H:%M:%S')}, \"\n",
    "          f\"T_speed: {epoch_per_second:4.3f}\"\n",
    "        )\n",
    "\n",
    "        self.wandb.log({\n",
    "          \"Epoch\": epoch,\n",
    "          \"Training loss\": train_loss,\n",
    "          \"Training accuracy (%)\": train_accuracy,\n",
    "          \"Validation loss\": validation_loss,\n",
    "          \"Validation accuracy (%)\": validation_accuracy,\n",
    "          \"Best Validation accuracy (%)\": max_val_accuracy,\n",
    "          \"Best Validation epoch\": best_epoch,\n",
    "          \"Training speed (epochs/sec.)\": epoch_per_second,\n",
    "        })\n",
    "\n",
    "        if early_stop:\n",
    "          break\n",
    "\n",
    "    elapsed_time = datetime.now() - training_start_time\n",
    "    print(f\"Final training time: {strfdelta(elapsed_time, '%H:%M:%S')}\")\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "def get_parser():\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--wandb\", action=argparse.BooleanOptionalAction, default=False, help=\"True or False\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-b\", \"--batch_size\", type=int, default=2_048, help=\"Batch size (int, default: 2_048)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-e\", \"--epochs\", type=int, default=10_000, help=\"Number of training epochs (int, default:10_000)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-r\", \"--learning_rate\", type=float, default=1e-3, help=\"Learning rate (float, default: 1e-3)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-v\", \"--validation_intervals\", type=int, default=10,\n",
    "    help=\"Number of training epochs between validations (int, default: 10)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-p\", \"--early_stop_patience\", type=int, default=10,\n",
    "    help=\"Number of early stop patience (int, default: 10)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-d\", \"--early_stop_delta\", type=float, default=0.00001,\n",
    "    help=\"Delta value of early stop (float, default: 0.00001)\"\n",
    "  )\n",
    "\n",
    "  return parser\n",
    "\n",
    "def get_fashion_mnist_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
    "\n",
    "    # print(\"Num Train Samples: \", len(f_mnist_train))\n",
    "    # print(\"Num Validation Samples: \", len(f_mnist_validation))\n",
    "    # print(\"Sample Shape: \", f_mnist_train[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    # num_data_loading_workers = get_num_cpu_cores()\n",
    "    num_data_loading_workers = 0\n",
    "\n",
    "    # print(\"Number of Data Loading Workers:\", num_data_loading_workers)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2860, std=0.3529),\n",
    "    )\n",
    "\n",
    "    return train_data_loader, validation_data_loader, f_mnist_transforms\n",
    "\n",
    "\n",
    "def get_fashion_mnist_test_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
    "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
    "    print(\"Sample Shape: \", f_mnist_test[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test))\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2860, std=0.3529),\n",
    "    )\n",
    "\n",
    "    return f_mnist_test_images, test_data_loader, f_mnist_transforms\n",
    "\n",
    "def get_resnet_model(num_classes=10, dropout_rate=0.5):\n",
    "    class ResnetBlock(nn.Module):\n",
    "        def __init__(self, out_channels, stride=1, downsample=None):\n",
    "            super(ResnetBlock, self).__init__()\n",
    "            self.conv1 = nn.LazyConv2d(out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.LazyBatchNorm2d()\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.conv2 = nn.LazyConv2d(out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.LazyBatchNorm2d()\n",
    "            self.downsample = downsample\n",
    "\n",
    "        def forward(self, x):\n",
    "            identity = x\n",
    "\n",
    "            out = self.conv1(x)\n",
    "            out = self.bn1(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "            out = self.conv2(out)\n",
    "            out = self.bn2(out)\n",
    "\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "\n",
    "            out += identity\n",
    "            out = self.relu(out)\n",
    "\n",
    "            return out\n",
    "\n",
    "    class ResNet(nn.Module):\n",
    "        def __init__(self, dropout_p=0.0):\n",
    "            super(ResNet, self).__init__()\n",
    "            # Fashion MNIST 28x28이기에 맞춰서 3x3 Conv 사용\n",
    "            self.conv1 = nn.LazyConv2d(64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.LazyBatchNorm2d()\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            # ResNet Layers\n",
    "            self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "            self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "            self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "            self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "            self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "            self.fc = nn.LazyLinear(num_classes)\n",
    "\n",
    "            self.dropout = nn.Dropout(p=dropout_p)\n",
    "            self.fc = nn.LazyLinear(num_classes)\n",
    "\n",
    "        def _make_layer(self, out_channels, blocks, stride):\n",
    "            downsample = None\n",
    "\n",
    "            if stride != 1:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.LazyConv2d(out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.LazyBatchNorm2d()\n",
    "                )\n",
    "\n",
    "            layers = []\n",
    "            layers.append(ResnetBlock(out_channels, stride=stride, downsample=downsample))\n",
    "\n",
    "            for _ in range(1, blocks):\n",
    "                layers.append(ResnetBlock(out_channels))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.layer4(x)\n",
    "\n",
    "            x = self.avg_pool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "\n",
    "    return ResNet(dropout_p=dropout_rate)\n",
    "\n",
    "def get_cnn_model():\n",
    "  class MyModel(nn.Module):\n",
    "    def __init__(self, in_channels, n_output):\n",
    "      super().__init__()\n",
    "\n",
    "      self.model = nn.Sequential(\n",
    "        # B x 1 x 28 x 28 --> B x 6 x (28 - 5 + 1) x (28 - 5 + 1) = B x 6 x 24 x 24\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=(5, 5), stride=(1, 1)),\n",
    "        # B x 6 x 24 x 24 --> B x 6 x 12 x 12\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.ReLU(),\n",
    "        # B x 6 x 12 x 12 --> B x 16 x (12 - 5 + 1) x (12 - 5 + 1) = B x 16 x 8 x 8\n",
    "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=(1, 1)),\n",
    "        # B x 16 x 8 x 8 --> B x 16 x 4 x 4\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.ReLU(),\n",
    "        # B x 16 x 4 x 4 --> B x 256\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, n_output),\n",
    "      )\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.model(x)\n",
    "      return x\n",
    "\n",
    "  # 1 * 28 * 28\n",
    "  my_model = MyModel(in_channels=1, n_output=10)\n",
    "\n",
    "  return my_model\n",
    "\n",
    "\n",
    "def main(args):\n",
    "  run_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  config = {\n",
    "    'epochs': args.epochs,\n",
    "    'batch_size': args.batch_size,\n",
    "    'validation_intervals': args.validation_intervals,\n",
    "    'learning_rate': args.learning_rate,\n",
    "    'early_stop_patience': args.early_stop_patience,\n",
    "    'early_stop_delta': args.early_stop_delta\n",
    "  }\n",
    "\n",
    "  project_name = \"cnn_fashion_mnist\"\n",
    "  wandb.init(\n",
    "    mode=\"online\" if args.wandb else \"disabled\",\n",
    "    project=project_name,\n",
    "    notes=\"mnist experiment with cnn\",\n",
    "    tags=[\"cnn\", \"fashion_mnist\"],\n",
    "    name=run_time_str,\n",
    "    config=config\n",
    "  )\n",
    "  print(args)\n",
    "  print(wandb.config)\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f\"Training on device {device}.\")\n",
    "\n",
    "  train_data_loader, validation_data_loader, mnist_transforms = get_fashion_mnist_data()\n",
    "  # model = get_cnn_model()\n",
    "  model = get_resnet_model(num_classes=10, dropout_rate=0.5)\n",
    "  model.to(device)\n",
    "\n",
    "  from torchinfo import summary\n",
    "  summary(model=model, input_size=(1, 1, 28, 28))\n",
    "\n",
    "  # 기존 SGD에서 Adam으로 변경\n",
    "  optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate, weight_decay=1e-3)\n",
    "  scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=wandb.config.epochs)\n",
    "\n",
    "  classification_trainer = ClassificationTrainer(\n",
    "    project_name, model, optimizer, train_data_loader, validation_data_loader, mnist_transforms,\n",
    "    run_time_str, wandb, device, CHECKPOINT_FILE_PATH\n",
    "  )\n",
    "  classification_trainer.train_loop(scheduler)\n",
    "\n",
    "  wandb.finish()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = get_parser()\n",
    "  args = parser.parse_args(args=[\"--wandb\", \"-b\", \"64\", \"-r\", \"1e-3\", \"-v\", \"10\"])\n",
    "  main(args)"
   ],
   "id": "ab905087b22034d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-11-22_23-06-39</strong> at: <a href='https://wandb.ai/kimwonho-/cnn_fashion_mnist/runs/rxalknxy' target=\"_blank\">https://wandb.ai/kimwonho-/cnn_fashion_mnist/runs/rxalknxy</a><br> View project at: <a href='https://wandb.ai/kimwonho-/cnn_fashion_mnist' target=\"_blank\">https://wandb.ai/kimwonho-/cnn_fashion_mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251122_230639-rxalknxy\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\leodi\\git\\link_dl\\_04_your_code\\wandb\\run-20251122_230650-3aza68iu</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimwonho-/cnn_fashion_mnist/runs/3aza68iu' target=\"_blank\">2025-11-22_23-06-50</a></strong> to <a href='https://wandb.ai/kimwonho-/cnn_fashion_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/kimwonho-/cnn_fashion_mnist' target=\"_blank\">https://wandb.ai/kimwonho-/cnn_fashion_mnist</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/kimwonho-/cnn_fashion_mnist/runs/3aza68iu' target=\"_blank\">https://wandb.ai/kimwonho-/cnn_fashion_mnist/runs/3aza68iu</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=True, batch_size=64, epochs=10000, learning_rate=0.001, validation_intervals=10, early_stop_patience=10, early_stop_delta=1e-05)\n",
      "{'epochs': 10000, 'batch_size': 64, 'validation_intervals': 10, 'learning_rate': 0.001, 'early_stop_patience': 10, 'early_stop_delta': 1e-05}\n",
      "Training on device cuda:0.\n",
      "[Epoch   1] T_loss: 0.45173, T_accuracy: 83.9618 | V_loss: 0.35312, V_accuracy: 87.2800 | Best V_Acc: 87.2800 at Epoch 1 | Early stopping is stated! | T_time: 00:00:31, T_speed: 0.032\n",
      "[Epoch  10] T_loss: 0.19558, T_accuracy: 93.1891 | V_loss: 0.26745, V_accuracy: 90.1200 | Best V_Acc: 90.1200 at Epoch 10 | V_loss decreased (0.35312 --> 0.26745). Saving model... | T_time: 00:04:58, T_speed: 0.034\n",
      "[Epoch  20] T_loss: 0.15520, T_accuracy: 94.6182 | V_loss: 0.20319, V_accuracy: 93.2400 | Best V_Acc: 93.2400 at Epoch 20 | V_loss decreased (0.26745 --> 0.20319). Saving model... | T_time: 00:09:56, T_speed: 0.034\n",
      "[Epoch  30] T_loss: 0.13630, T_accuracy: 95.3200 | V_loss: 0.21341, V_accuracy: 92.6600 | Best V_Acc: 93.2400 at Epoch 20 | Early stopping counter: 1 out of 10 | T_time: 00:14:57, T_speed: 0.033\n",
      "[Epoch  40] T_loss: 0.12738, T_accuracy: 95.7509 | V_loss: 0.23080, V_accuracy: 92.9000 | Best V_Acc: 93.2400 at Epoch 20 | Early stopping counter: 2 out of 10 | T_time: 00:19:56, T_speed: 0.033\n",
      "[Epoch  50] T_loss: 0.11759, T_accuracy: 96.1364 | V_loss: 0.23754, V_accuracy: 92.3600 | Best V_Acc: 93.2400 at Epoch 20 | Early stopping counter: 3 out of 10 | T_time: 00:24:45, T_speed: 0.034\n",
      "[Epoch  60] T_loss: 0.11768, T_accuracy: 96.0018 | V_loss: 0.25307, V_accuracy: 91.9000 | Best V_Acc: 93.2400 at Epoch 20 | Early stopping counter: 4 out of 10 | T_time: 00:29:43, T_speed: 0.034\n",
      "[Epoch  70] T_loss: 0.11173, T_accuracy: 96.2582 | V_loss: 0.23303, V_accuracy: 92.6200 | Best V_Acc: 93.2400 at Epoch 20 | Early stopping counter: 5 out of 10 | T_time: 00:34:03, T_speed: 0.034\n",
      "[Epoch  80] T_loss: 0.10562, T_accuracy: 96.5909 | V_loss: 0.25396, V_accuracy: 91.6600 | Best V_Acc: 93.2400 at Epoch 20 | Early stopping counter: 6 out of 10 | T_time: 00:38:40, T_speed: 0.034\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 519\u001B[0m\n\u001B[0;32m    517\u001B[0m parser \u001B[38;5;241m=\u001B[39m get_parser()\n\u001B[0;32m    518\u001B[0m args \u001B[38;5;241m=\u001B[39m parser\u001B[38;5;241m.\u001B[39mparse_args(args\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--wandb\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-b\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m64\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-r\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1e-3\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-v\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m10\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m--> 519\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[10], line 511\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m    505\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mCosineAnnealingLR(optimizer, T_max\u001B[38;5;241m=\u001B[39mwandb\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mepochs)\n\u001B[0;32m    507\u001B[0m classification_trainer \u001B[38;5;241m=\u001B[39m ClassificationTrainer(\n\u001B[0;32m    508\u001B[0m   project_name, model, optimizer, train_data_loader, validation_data_loader, mnist_transforms,\n\u001B[0;32m    509\u001B[0m   run_time_str, wandb, device, CHECKPOINT_FILE_PATH\n\u001B[0;32m    510\u001B[0m )\n\u001B[1;32m--> 511\u001B[0m \u001B[43mclassification_trainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    513\u001B[0m wandb\u001B[38;5;241m.\u001B[39mfinish()\n",
      "Cell \u001B[1;32mIn[10], line 214\u001B[0m, in \u001B[0;36mClassificationTrainer.train_loop\u001B[1;34m(self, scheduler)\u001B[0m\n\u001B[0;32m    211\u001B[0m best_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m--> 214\u001B[0m   train_loss, train_accuracy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m scheduler:\n\u001B[0;32m    217\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "Cell \u001B[1;32mIn[10], line 161\u001B[0m, in \u001B[0;36mClassificationTrainer.do_train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    158\u001B[0m   num_trains \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    160\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 161\u001B[0m   \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    162\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    164\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m loss_train \u001B[38;5;241m/\u001B[39m num_trains\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\link_dl\\lib\\site-packages\\torch\\_tensor.py:625\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    615\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    616\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    617\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    618\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    623\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    624\u001B[0m     )\n\u001B[1;32m--> 625\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    626\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\link_dl\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    349\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    351\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 354\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    362\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\link_dl\\lib\\site-packages\\torch\\autograd\\graph.py:841\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    839\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    840\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 841\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    842\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    843\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    844\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    845\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### [문제 2] 설명\n",
    "초기에는 기본적인 CNN 구조와 SGD 옵티마이저를 사용하여 학습을 시도했으나 목표하는 고성능을 달성하기에는 한계가 있었습니다. 이를 극복하고 Validation Accuracy를 최대한 끌어올리기 위해 다음과 같이 모델 구조와 하이퍼파라미터를 수정했습니다.\n",
    "최종적으로 배치 사이즈는 64, 학습률은 1e-3, 옵티마이저는 SGD에서 Adam으로 변경했고 Resnet 모델을 이용하도록 변경했습니다.\n",
    "최종적으로 94%는 못넘겼지만, 93.24라는 가장 높은 Validation 값을 기록했습니다.\n"
   ],
   "id": "2d89b5a7f1bb577d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [문제 3] 학습 완료된 모델로 테스트 데이터 Accuracy 확인하기",
   "id": "ea8cd11147b42d8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:46:58.700824Z",
     "start_time": "2025-11-22T14:46:54.469940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "BASE_PATH = \"/Users/leodi/git/link_dl\"\n",
    "if BASE_PATH not in sys.path:\n",
    "    sys.path.append(BASE_PATH)\n",
    "\n",
    "CURRENT_FILE_PATH = os.getcwd()\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_fashion_mnist_test_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=0.2860, std=0.3529),\n",
    "    ])\n",
    "\n",
    "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=test_transform)\n",
    "\n",
    "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
    "\n",
    "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=1000, shuffle=False)\n",
    "\n",
    "    return None, test_data_loader, None\n",
    "\n",
    "def get_resnet_model(num_classes=10, dropout_rate=0.5):\n",
    "    class ResnetBlock(nn.Module):\n",
    "        def __init__(self, out_channels, stride=1, downsample=None):\n",
    "            super(ResnetBlock, self).__init__()\n",
    "            self.conv1 = nn.LazyConv2d(out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.LazyBatchNorm2d()\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.conv2 = nn.LazyConv2d(out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.LazyBatchNorm2d()\n",
    "            self.downsample = downsample\n",
    "\n",
    "        def forward(self, x):\n",
    "            identity = x\n",
    "\n",
    "            out = self.conv1(x)\n",
    "            out = self.bn1(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "            out = self.conv2(out)\n",
    "            out = self.bn2(out)\n",
    "\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "\n",
    "            out += identity\n",
    "            out = self.relu(out)\n",
    "\n",
    "            return out\n",
    "\n",
    "    class ResNet(nn.Module):\n",
    "        def __init__(self, dropout_p=0.0):\n",
    "            super(ResNet, self).__init__()\n",
    "            # Fashion MNIST 28x28이기에 맞춰서 3x3 Conv 사용\n",
    "            self.conv1 = nn.LazyConv2d(64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.LazyBatchNorm2d()\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "            # ResNet Layers\n",
    "            self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "            self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "            self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "            self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "            self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "            self.fc = nn.LazyLinear(num_classes)\n",
    "\n",
    "            self.dropout = nn.Dropout(p=dropout_p)\n",
    "            self.fc = nn.LazyLinear(num_classes)\n",
    "\n",
    "        def _make_layer(self, out_channels, blocks, stride):\n",
    "            downsample = None\n",
    "\n",
    "            if stride != 1:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.LazyConv2d(out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.LazyBatchNorm2d()\n",
    "                )\n",
    "\n",
    "            layers = []\n",
    "            layers.append(ResnetBlock(out_channels, stride=stride, downsample=downsample))\n",
    "\n",
    "            for _ in range(1, blocks):\n",
    "                layers.append(ResnetBlock(out_channels))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.layer4(x)\n",
    "\n",
    "            x = self.avg_pool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "\n",
    "    return ResNet(dropout_p=dropout_rate)\n",
    "\n",
    "def find_best_checkpoint(checkpoint_dir):\n",
    "    if not os.path.exists(checkpoint_dir): return None\n",
    "    files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pt')]\n",
    "    if not files: return None\n",
    "    files.sort(key=lambda x: os.path.getmtime(os.path.join(checkpoint_dir, x)), reverse=True)\n",
    "    return os.path.join(checkpoint_dir, files[0])\n",
    "\n",
    "def main():\n",
    "    print(\"======== Test & Visualization ========\")\n",
    "    _, test_loader, _ = get_fashion_mnist_test_data()\n",
    "\n",
    "    model = get_resnet_model(num_classes=10, dropout_rate=0.5)\n",
    "    model.to(device)\n",
    "\n",
    "    print(\">> Initializing Lazy Modules...\")\n",
    "    model(torch.randn(1, 1, 28, 28).to(device))\n",
    "\n",
    "    checkpoint_path = find_best_checkpoint(CHECKPOINT_FILE_PATH)\n",
    "    if checkpoint_path:\n",
    "        print(f\">> Loading Weights from: {checkpoint_path}\")\n",
    "        model.load_state_dict(torch.load(checkpoint_path))\n",
    "    else:\n",
    "        print(\"[Error] Checkpoint file not found\")\n",
    "        return\n",
    "\n",
    "    dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "    _ = model(dummy_input)\n",
    "\n",
    "    model.eval()\n",
    "    all_imgs, all_lbls, all_preds = [], [], []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in test_loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            total += lbls.size(0)\n",
    "            correct += (preds == lbls).sum().item()\n",
    "\n",
    "            all_imgs.append(imgs.cpu())\n",
    "            all_lbls.append(lbls.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"\\n>> Final Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    print(f\"*\" * 50)\n",
    "\n",
    "    print(\"\\n>> [문제 4] Visualizing 10 Samples...\")\n",
    "    all_imgs = torch.cat(all_imgs)\n",
    "    all_lbls = torch.cat(all_lbls)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "\n",
    "    incorrect_indices = (all_preds != all_lbls).nonzero(as_tuple=True)[0]\n",
    "    selected_indices = []\n",
    "\n",
    "    if len(incorrect_indices) > 0:\n",
    "        idx = incorrect_indices[torch.randint(len(incorrect_indices), (1,)).item()]\n",
    "        selected_indices.append(idx.item())\n",
    "\n",
    "    perm = torch.randperm(len(all_imgs))\n",
    "    for i in perm:\n",
    "        if len(selected_indices) == 10: break\n",
    "        if i.item() not in selected_indices:\n",
    "            selected_indices.append(i.item())\n",
    "\n",
    "    classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        # 이미지 역정규화\n",
    "        img = all_imgs[idx].squeeze().numpy() * 0.3529 + 0.2860\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        lbl, pred = all_lbls[idx].item(), all_preds[idx].item()\n",
    "\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        color = 'blue' if lbl == pred else 'red'\n",
    "        axes[i].set_title(f\"True: {classes[lbl]}\\nPred: {classes[pred]}\", color=color, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "        if lbl != pred:\n",
    "             print(f\">> [Review] Image {i+1}: True({classes[lbl]}) vs Pred({classes[pred]})\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "fba3d91669bb5d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Test & Visualization ========\n",
      "Num Test Samples:  10000\n",
      ">> Initializing Lazy Modules...\n",
      ">> Loading Weights from: C:\\Users\\leodi\\git\\link_dl\\_04_your_code\\checkpoints\\cnn_fashion_mnist_checkpoint_latest.pt\n",
      "\n",
      ">> Final Test Accuracy: 92.62%\n",
      "**************************************************\n",
      "\n",
      ">> [문제 4] Visualizing 10 Samples...\n",
      ">> [Review] Image 1: True(T-shirt/top) vs Pred(Pullover)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 10 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### [문제 3] 결과 설명\n",
    "먼저 학습 과정에서 검증 정확도가 가장 높았던 최적의 모델 파일을 로드하여 학습에 사용하지 않은 테스트 데이터 1만 장에 대해 성능 평가를 수행했습니다.\n",
    "\n",
    "ResNet 기반 모델 구조를 적용하여 학습한 결과 최종 테스트 정확도는 92.62%를 기록했습니다. 비록 목표 점수인 93%에는 아주 조금 미치지 못했지만, 10가지 패션 아이템 대부분을 알맞게 분류하고 있음을 확인했습니다."
   ],
   "id": "304ef2e1c2d53684"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [문제 4] 샘플 테스트 데이터 분류 예측 결과 확인하기",
   "id": "ae5724c736c188e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "테스트 데이터 중 무작위로 10개의 샘플을 추출하여 실제 정답과 모델의 예측값을 비교했습니다. 대부분의 이미지를 정확하게 맞추었으나 일부 샘플에서 예측과 정답이 다른 경우가 있었습니다.\n",
    "\n",
    "특히 T-shirt/top을 Pullover로 잘못 예측하는 문제가 발생했습니다. 제 생각에는 두 가지 모두 상의에 해당하며, Fashion MNIST 이미지 특성상 해상도가 낮아 소매의 길이나 옷감의 두께 같은 특징이 뚜렷하게 구분되지 않기 때문이라고 생각합니다. 모델이 전체적인 실루엣만 보고 판단하다 보니 이 두 가지를 혼동하는 경우가 생기는 것 같습니다."
   ],
   "id": "f9d214838734f69f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [숙제 후기]",
   "id": "ccabbfc78d72dd77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "이번 과제는 수업 시간에 이론으로만 접했던 CNN과 ResNet 같은 최신 아키텍처를 직접 구현하고 패션 MNIST 데이터셋에 적용해보며 딥러닝 모델의 성능을 극대화해보는 과정이었습니다. 단순히 모델을 돌리는 것을 넘어 목표 정확도인 94퍼센트를 달성하기 위해 다양한 기법을 시도하며 많은 시행착오를 겪었습니다.",
   "id": "e3bfef7b21fc4caa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "가장 기억에 남는 부분은 2번 문제입니다. 2번 문제를 풀면서 목표로 퍼센트를 넘기기 위해서 배치 사이즈나 학습률 등 여러가지 요소를 변경하거나 model을 변경해보는 과정이 시간도 오래 걸렸고 테스트도 매번 해보면서 비교를 해봐야 했기에 힘들었어서 가장 기억에 남는 것 같습니다.",
   "id": "b30ae172b7f8b398"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "마지막으로, 예측과 정답이 다른 경우를 보고서 생각해보는 과정을 통해 어떻게 해야지 이렇게 유사한 경우에도 구별을 할 수 있을지 더 고민하게 되었습니다.",
   "id": "e36d35dc2dff8bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
